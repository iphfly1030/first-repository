{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "sophisticated-filling",
   "metadata": {},
   "source": [
    "# Step 1. 데이터 다운로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "complex-southwest",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-01-26 11:44:53--  https://aiffelstaticprd.blob.core.windows.net/media/documents/song_lyrics.zip\n",
      "Resolving aiffelstaticprd.blob.core.windows.net (aiffelstaticprd.blob.core.windows.net)... 52.239.148.4\n",
      "Connecting to aiffelstaticprd.blob.core.windows.net (aiffelstaticprd.blob.core.windows.net)|52.239.148.4|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 2101791 (2.0M) [application/zip]\n",
      "Saving to: ‘song_lyrics.zip’\n",
      "\n",
      "song_lyrics.zip     100%[===================>]   2.00M  11.8MB/s    in 0.2s    \n",
      "\n",
      "2021-01-26 11:44:54 (11.8 MB/s) - ‘song_lyrics.zip’ saved [2101791/2101791]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! wget https://aiffelstaticprd.blob.core.windows.net/media/documents/song_lyrics.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "confident-hearts",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  song_lyrics.zip\n",
      "  inflating: /home/aiffel-dj43/aiffel/lyricist/data/lyrics/Kanye_West.txt  \n",
      "  inflating: /home/aiffel-dj43/aiffel/lyricist/data/lyrics/Lil_Wayne.txt  \n",
      "  inflating: /home/aiffel-dj43/aiffel/lyricist/data/lyrics/adele.txt  \n",
      "  inflating: /home/aiffel-dj43/aiffel/lyricist/data/lyrics/al-green.txt  \n",
      "  inflating: /home/aiffel-dj43/aiffel/lyricist/data/lyrics/alicia-keys.txt  \n",
      "  inflating: /home/aiffel-dj43/aiffel/lyricist/data/lyrics/amy-winehouse.txt  \n",
      "  inflating: /home/aiffel-dj43/aiffel/lyricist/data/lyrics/beatles.txt  \n",
      "  inflating: /home/aiffel-dj43/aiffel/lyricist/data/lyrics/bieber.txt  \n",
      "  inflating: /home/aiffel-dj43/aiffel/lyricist/data/lyrics/bjork.txt  \n",
      "  inflating: /home/aiffel-dj43/aiffel/lyricist/data/lyrics/blink-182.txt  \n",
      "  inflating: /home/aiffel-dj43/aiffel/lyricist/data/lyrics/bob-dylan.txt  \n",
      "  inflating: /home/aiffel-dj43/aiffel/lyricist/data/lyrics/bob-marley.txt  \n",
      "  inflating: /home/aiffel-dj43/aiffel/lyricist/data/lyrics/britney-spears.txt  \n",
      "  inflating: /home/aiffel-dj43/aiffel/lyricist/data/lyrics/bruce-springsteen.txt  \n",
      "  inflating: /home/aiffel-dj43/aiffel/lyricist/data/lyrics/bruno-mars.txt  \n",
      "  inflating: /home/aiffel-dj43/aiffel/lyricist/data/lyrics/cake.txt  \n",
      "  inflating: /home/aiffel-dj43/aiffel/lyricist/data/lyrics/dickinson.txt  \n",
      "  inflating: /home/aiffel-dj43/aiffel/lyricist/data/lyrics/disney.txt  \n",
      "  inflating: /home/aiffel-dj43/aiffel/lyricist/data/lyrics/dj-khaled.txt  \n",
      "  inflating: /home/aiffel-dj43/aiffel/lyricist/data/lyrics/dolly-parton.txt  \n",
      "  inflating: /home/aiffel-dj43/aiffel/lyricist/data/lyrics/dr-seuss.txt  \n",
      "  inflating: /home/aiffel-dj43/aiffel/lyricist/data/lyrics/drake.txt  \n",
      "  inflating: /home/aiffel-dj43/aiffel/lyricist/data/lyrics/eminem.txt  \n",
      "  inflating: /home/aiffel-dj43/aiffel/lyricist/data/lyrics/janisjoplin.txt  \n",
      "  inflating: /home/aiffel-dj43/aiffel/lyricist/data/lyrics/jimi-hendrix.txt  \n",
      "  inflating: /home/aiffel-dj43/aiffel/lyricist/data/lyrics/johnny-cash.txt  \n",
      "  inflating: /home/aiffel-dj43/aiffel/lyricist/data/lyrics/joni-mitchell.txt  \n",
      "  inflating: /home/aiffel-dj43/aiffel/lyricist/data/lyrics/kanye-west.txt  \n",
      "  inflating: /home/aiffel-dj43/aiffel/lyricist/data/lyrics/kanye.txt  \n",
      "  inflating: /home/aiffel-dj43/aiffel/lyricist/data/lyrics/lady-gaga.txt  \n",
      "  inflating: /home/aiffel-dj43/aiffel/lyricist/data/lyrics/leonard-cohen.txt  \n",
      "  inflating: /home/aiffel-dj43/aiffel/lyricist/data/lyrics/lil-wayne.txt  \n",
      "  inflating: /home/aiffel-dj43/aiffel/lyricist/data/lyrics/lin-manuel-miranda.txt  \n",
      "  inflating: /home/aiffel-dj43/aiffel/lyricist/data/lyrics/lorde.txt  \n",
      "  inflating: /home/aiffel-dj43/aiffel/lyricist/data/lyrics/ludacris.txt  \n",
      "  inflating: /home/aiffel-dj43/aiffel/lyricist/data/lyrics/michael-jackson.txt  \n",
      "  inflating: /home/aiffel-dj43/aiffel/lyricist/data/lyrics/missy-elliott.txt  \n",
      "  inflating: /home/aiffel-dj43/aiffel/lyricist/data/lyrics/nickelback.txt  \n",
      "  inflating: /home/aiffel-dj43/aiffel/lyricist/data/lyrics/nicki-minaj.txt  \n",
      "  inflating: /home/aiffel-dj43/aiffel/lyricist/data/lyrics/nirvana.txt  \n",
      "  inflating: /home/aiffel-dj43/aiffel/lyricist/data/lyrics/notorious-big.txt  \n",
      "  inflating: /home/aiffel-dj43/aiffel/lyricist/data/lyrics/notorious_big.txt  \n",
      "  inflating: /home/aiffel-dj43/aiffel/lyricist/data/lyrics/nursery_rhymes.txt  \n",
      "  inflating: /home/aiffel-dj43/aiffel/lyricist/data/lyrics/patti-smith.txt  \n",
      "  inflating: /home/aiffel-dj43/aiffel/lyricist/data/lyrics/paul-simon.txt  \n",
      "  inflating: /home/aiffel-dj43/aiffel/lyricist/data/lyrics/prince.txt  \n",
      "  inflating: /home/aiffel-dj43/aiffel/lyricist/data/lyrics/r-kelly.txt  \n",
      "  inflating: /home/aiffel-dj43/aiffel/lyricist/data/lyrics/radiohead.txt  \n",
      "  inflating: /home/aiffel-dj43/aiffel/lyricist/data/lyrics/rihanna.txt  \n"
     ]
    }
   ],
   "source": [
    "! unzip song_lyrics.zip -d ~/aiffel/lyricist/data/lyrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "soviet-spank",
   "metadata": {},
   "source": [
    "# Step 2. 데이터 읽어오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "rising-following",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터 크기: 187088\n",
      "Examples:\n",
      " ['They say get ready for the revolution', \"I think it's time we find some sorta solution\", \"Somebody's caught up in the endless pollution\", 'They need to wake up, stop living illusions I know you need to hear this', \"Why won't somebody feel this\", 'This is my wish that we all feel connected', 'This is my wish that nobodies neglected Be like a rocket baby', 'Be like a rocket Take off', 'Just fly, away (ay, ay)', 'To find your space Take off']\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "txt_file_path = os.getenv('HOME')+'/aiffel/lyricist/data/lyrics/*'\n",
    "\n",
    "txt_list = glob.glob(txt_file_path)\n",
    "\n",
    "raw_corpus = []\n",
    "\n",
    "# 여러개의 txt 파일을 모두 읽어서 raw_corpus 에 담습니다.\n",
    "for txt_file in txt_list:\n",
    "    with open(txt_file, \"r\") as f:\n",
    "        raw = f.read().splitlines()\n",
    "        raw_corpus.extend(raw)\n",
    "\n",
    "print(\"데이터 크기:\", len(raw_corpus))\n",
    "print(\"Examples:\\n\", raw_corpus[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "departmental-april",
   "metadata": {},
   "source": [
    "6-4에서 데이터를 불러올때는 **re, numpy, tensorflow**를 함께 가져왔는데 왜 여기서는 **glob**만 사용하는지 궁금하다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "explicit-illinois",
   "metadata": {},
   "source": [
    "### 연극 대사를 토큰화하면 화자와 공백이 포함되기 때문에 그 부분을 제거해야했는데 lyrics 데이터의 경우 문장 단위로 토큰화 되고 있기 때문에 다른 방식의 데이터 처리가 필요할 것으로 보인다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adolescent-printing",
   "metadata": {},
   "source": [
    "# Step 3. 데이터 정제"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "capital-circular",
   "metadata": {},
   "source": [
    "1. 토큰화 했을 때 토큰의 개수가 15개를 넘어가는 문장을 학습데이터에서 제외하는 것을 권장  \n",
    "\n",
    "2. preprocess_sentence()  함수 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pursuant-solid",
   "metadata": {},
   "source": [
    "### preprocess_sentence() 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "individual-resource",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<start> this is sample sentence . <end>\n"
     ]
    }
   ],
   "source": [
    "import re                   \n",
    "import numpy as np         \n",
    "import tensorflow as tf    \n",
    "\n",
    "def preprocess_sentence(sentence):\n",
    "    sentence = sentence.lower().strip()       \n",
    "    sentence = re.sub(r\"([?.!,¿])\", r\" \\1 \", sentence)        \n",
    "    sentence = re.sub(r'[\" \"]+', \" \", sentence)                  \n",
    "    sentence = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", sentence)  \n",
    "    sentence = sentence.strip()\n",
    "\n",
    "    sentence = '<start> ' + sentence + ' <end>'      \n",
    "    return sentence\n",
    "\n",
    "print(preprocess_sentence(\"This @_is ;;;sample        sentence.\"))   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "super-sleep",
   "metadata": {},
   "source": [
    "#### re를 import하지 않아서 처음에 오류가 났다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "detected-translator",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<start> they say get ready for the revolution <end>',\n",
       " '<start> i think it s time we find some sorta solution <end>',\n",
       " '<start> somebody s caught up in the endless pollution <end>',\n",
       " '<start> why won t somebody feel this <end>',\n",
       " '<start> this is my wish that we all feel connected <end>',\n",
       " '<start> this is my wish that nobodies neglected be like a rocket baby <end>',\n",
       " '<start> be like a rocket take off <end>',\n",
       " '<start> just fly , away ay , ay <end>',\n",
       " '<start> to find your space take off <end>',\n",
       " '<start> just fly , away ay , ay <end>']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = []\n",
    "\n",
    "for sentence in raw_corpus:\n",
    "    if len(sentence) == 0: continue\n",
    "    if sentence[-1] == \":\": continue\n",
    "    \n",
    "    hong = preprocess_sentence(sentence)\n",
    "    if len(hong.split(' ')) >= 15: continue\n",
    "    corpus.append(preprocess_sentence(sentence))\n",
    "        \n",
    "corpus[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "western-summit",
   "metadata": {},
   "source": [
    "#### hong = preprocess_sentence(sentence)\n",
    "####    if len(hong.split(' ')) >= 15: continue  \n",
    "\n",
    "수희님의 도움으로 토큰이 15보다 큰 문장을 제외시킬수 있었다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "favorite-tongue",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  2  38  71 ...   0   0   0]\n",
      " [  2   4 131 ...   3   0   0]\n",
      " [  2 243  17 ...   0   0   0]\n",
      " ...\n",
      " [  2 146  50 ...   0   0   0]\n",
      " [  2 146   5 ...   0   0   0]\n",
      " [  2 146   5 ...   3   0   0]] <keras_preprocessing.text.Tokenizer object at 0x7fcf3226d050>\n"
     ]
    }
   ],
   "source": [
    "def tokenize(corpus):\n",
    "   \n",
    "    tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
    "        num_words=12000,   \n",
    "        filters=' ',    \n",
    "        oov_token=\"<unk>\"  \n",
    "    )\n",
    "    tokenizer.fit_on_texts(corpus)   \n",
    "    \n",
    "    tensor = tokenizer.texts_to_sequences(corpus)   \n",
    "\n",
    "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='post')  \n",
    "\n",
    "    print(tensor,tokenizer)\n",
    "    return tensor, tokenizer\n",
    "\n",
    "tensor, tokenizer = tokenize(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "european-trance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 : <unk>\n",
      "2 : <start>\n",
      "3 : <end>\n",
      "4 : i\n",
      "5 : ,\n",
      "6 : the\n",
      "7 : you\n",
      "8 : and\n",
      "9 : a\n",
      "10 : to\n",
      "11 : it\n",
      "12 : me\n",
      "13 : my\n",
      "14 : in\n",
      "15 : that\n"
     ]
    }
   ],
   "source": [
    "for idx in tokenizer.index_word:\n",
    "    print(idx, \":\", tokenizer.index_word[idx])\n",
    "\n",
    "    if idx >= 15: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "documented-general",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   2   38   71   43  302   28    6 3267    3    0    0    0    0]\n",
      "[  38   71   43  302   28    6 3267    3    0    0    0    0    0]\n"
     ]
    }
   ],
   "source": [
    "src_input = tensor[:, :-1]  \n",
    "tgt_input = tensor[:, 1:]    \n",
    "print(src_input[0])\n",
    "print(tgt_input[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "white-cleaning",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((256, 13), (256, 13)), types: (tf.int32, tf.int32)>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BUFFER_SIZE = len(src_input)\n",
    "BATCH_SIZE = 256\n",
    "steps_per_epoch = len(src_input) // BATCH_SIZE\n",
    "\n",
    "VOCAB_SIZE = tokenizer.num_words + 1\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((src_input, tgt_input)).shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "elegant-block",
   "metadata": {},
   "source": [
    "# Step 4. 평가 데이터셋 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "economic-briefing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source Train: (119992, 13)\n",
      "Target Train: (119992, 13)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "enc_train, enc_val, dec_train, dec_val = train_test_split(src_input, \n",
    "                                                    tgt_input, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=7)\n",
    "\n",
    "print(\"Source Train:\", enc_train.shape)\n",
    "print(\"Target Train:\", dec_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aware-dance",
   "metadata": {},
   "source": [
    "# Step 5. 인공지능 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "moral-retention",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextGenerator(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_size, hidden_size):\n",
    "        super(TextGenerator, self).__init__()\n",
    "        \n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_size)\n",
    "        self.rnn_1 = tf.keras.layers.LSTM(hidden_size, return_sequences=True)\n",
    "        self.rnn_2 = tf.keras.layers.LSTM(hidden_size, return_sequences=True)\n",
    "        self.linear = tf.keras.layers.Dense(vocab_size)\n",
    "        \n",
    "    def call(self, x):\n",
    "        out = self.embedding(x)\n",
    "        out = self.rnn_1(out)\n",
    "        out = self.rnn_2(out)\n",
    "        out = self.linear(out)\n",
    "        \n",
    "        return out\n",
    "    \n",
    "embedding_size = 256\n",
    "hidden_size = 1024\n",
    "model = TextGenerator(tokenizer.num_words + 1, embedding_size , hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "distinct-wellington",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(256, 13, 12001), dtype=float32, numpy=\n",
       "array([[[-2.09648235e-04, -1.07291664e-04, -2.19581143e-05, ...,\n",
       "         -2.45101110e-04, -1.00813922e-04, -8.32458391e-05],\n",
       "        [-4.70935425e-04, -2.70313059e-04,  9.80467462e-07, ...,\n",
       "         -3.25021159e-04, -1.62004246e-04, -2.10396465e-04],\n",
       "        [-5.36043313e-04, -3.76809738e-04,  1.01514030e-04, ...,\n",
       "         -2.56084226e-04, -6.73801769e-05, -3.17077793e-04],\n",
       "        ...,\n",
       "        [-8.51757650e-04, -1.11408951e-03,  1.07909371e-04, ...,\n",
       "         -1.09855307e-03, -5.11018909e-04, -8.11893377e-04],\n",
       "        [-8.72444187e-04, -9.78386262e-04, -6.07385955e-05, ...,\n",
       "         -1.27468607e-03, -5.61323250e-04, -1.11464551e-03],\n",
       "        [-7.80551462e-04, -7.56925670e-04,  4.66928941e-05, ...,\n",
       "         -1.13799341e-03, -6.64370542e-04, -1.49247202e-03]],\n",
       "\n",
       "       [[-2.09648235e-04, -1.07291664e-04, -2.19581143e-05, ...,\n",
       "         -2.45101110e-04, -1.00813922e-04, -8.32458391e-05],\n",
       "        [-6.85223931e-05, -4.01761645e-05,  2.93999881e-04, ...,\n",
       "         -3.38901940e-04, -2.11320061e-04, -1.56467751e-04],\n",
       "        [-7.06022256e-05, -9.58197270e-05,  3.99584358e-04, ...,\n",
       "         -2.54014070e-04, -2.92235054e-04, -1.34002694e-04],\n",
       "        ...,\n",
       "        [ 4.78174159e-04,  1.63325458e-04,  1.03988941e-03, ...,\n",
       "          5.41816589e-05, -5.09353937e-04, -1.22579862e-03],\n",
       "        [ 5.29595360e-04,  3.07048729e-04,  1.18944119e-03, ...,\n",
       "          4.28963453e-04, -6.85639679e-04, -1.68508885e-03],\n",
       "        [ 5.47839853e-04,  4.36817587e-04,  1.32742303e-03, ...,\n",
       "          8.10117403e-04, -8.31040845e-04, -2.12382502e-03]],\n",
       "\n",
       "       [[-2.09648235e-04, -1.07291664e-04, -2.19581143e-05, ...,\n",
       "         -2.45101110e-04, -1.00813922e-04, -8.32458391e-05],\n",
       "        [-4.99275047e-04, -1.26179468e-04,  9.83646969e-05, ...,\n",
       "         -4.75626002e-04, -2.45362986e-04, -3.03130917e-04],\n",
       "        [-3.98230826e-04,  1.50176620e-05,  4.82154341e-04, ...,\n",
       "         -5.84140013e-04, -3.24373046e-04, -4.55348520e-04],\n",
       "        ...,\n",
       "        [-8.30330246e-05, -5.79351617e-04, -1.25922988e-05, ...,\n",
       "          6.73870440e-04, -8.30323435e-04, -1.66707218e-03],\n",
       "        [-1.65544727e-04, -8.05655320e-04,  1.79146344e-04, ...,\n",
       "          5.44345705e-04, -9.62331018e-04, -1.76079792e-03],\n",
       "        [-1.14224749e-04, -8.77842307e-04,  2.51608726e-04, ...,\n",
       "          6.47333742e-04, -9.89145250e-04, -1.87957485e-03]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[-2.09648235e-04, -1.07291664e-04, -2.19581143e-05, ...,\n",
       "         -2.45101110e-04, -1.00813922e-04, -8.32458391e-05],\n",
       "        [-4.99275047e-04, -1.26179468e-04,  9.83646969e-05, ...,\n",
       "         -4.75626002e-04, -2.45362986e-04, -3.03130917e-04],\n",
       "        [-8.36513238e-04, -2.59501976e-04, -1.01061167e-04, ...,\n",
       "         -7.87709490e-04, -4.87772835e-04, -5.31569531e-04],\n",
       "        ...,\n",
       "        [ 3.21078987e-04, -4.82199830e-04,  9.78765427e-04, ...,\n",
       "          1.10273412e-03, -6.82326150e-04, -2.42883735e-03],\n",
       "        [ 4.22165729e-04, -2.54110812e-04,  1.19357079e-03, ...,\n",
       "          1.42782822e-03, -7.76340894e-04, -2.76762433e-03],\n",
       "        [ 4.82728821e-04, -4.32054985e-05,  1.36808574e-03, ...,\n",
       "          1.73106615e-03, -8.62766465e-04, -3.06568039e-03]],\n",
       "\n",
       "       [[-2.09648235e-04, -1.07291664e-04, -2.19581143e-05, ...,\n",
       "         -2.45101110e-04, -1.00813922e-04, -8.32458391e-05],\n",
       "        [-4.66150552e-04, -2.54845480e-04,  2.44808238e-04, ...,\n",
       "         -3.62896797e-04, -8.20988207e-05, -6.21528525e-05],\n",
       "        [-5.58905012e-04, -1.02693572e-04,  6.67139306e-04, ...,\n",
       "          5.12113220e-05,  1.00262776e-04, -5.62689820e-05],\n",
       "        ...,\n",
       "        [ 5.66693125e-05,  6.98849908e-04, -3.62667488e-04, ...,\n",
       "          1.25982543e-03, -5.36694250e-04,  2.07914869e-04],\n",
       "        [ 1.69278923e-04,  5.59698325e-04, -2.20620277e-04, ...,\n",
       "          1.36474695e-03, -7.98476278e-04, -2.04800614e-04],\n",
       "        [ 2.93019868e-04,  4.92134423e-04,  6.20602950e-05, ...,\n",
       "          1.54324889e-03, -1.05595286e-03, -6.76460797e-04]],\n",
       "\n",
       "       [[-2.09648235e-04, -1.07291664e-04, -2.19581143e-05, ...,\n",
       "         -2.45101110e-04, -1.00813922e-04, -8.32458391e-05],\n",
       "        [-2.22495975e-04, -2.35923289e-04, -3.41278974e-05, ...,\n",
       "         -2.85350456e-04, -7.64689030e-05, -1.38001182e-04],\n",
       "        [-4.21621749e-04, -4.59620496e-04, -2.92216515e-04, ...,\n",
       "         -4.88080637e-04, -2.63239781e-04, -2.57332111e-04],\n",
       "        ...,\n",
       "        [-3.79196601e-04, -4.19207558e-04,  4.83213487e-04, ...,\n",
       "          1.94345135e-03,  3.75801203e-04,  5.26639342e-04],\n",
       "        [-5.06569457e-04, -7.12618115e-04,  3.74512252e-04, ...,\n",
       "          2.06962600e-03,  3.62169987e-04,  5.68468706e-04],\n",
       "        [-5.29052806e-04, -8.54378683e-04,  1.86551057e-04, ...,\n",
       "          1.92457647e-03,  2.67960218e-04,  2.29059297e-04]]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for src_sample, tgt_sample in dataset.take(1): break\n",
    "model(src_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "searching-dylan",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"text_generator\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        multiple                  3072256   \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  multiple                  5246976   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                multiple                  8392704   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                multiple                  12301025  \n",
      "=================================================================\n",
      "Total params: 29,012,961\n",
      "Trainable params: 29,012,961\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "instructional-interference",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "585/585 [==============================] - 70s 119ms/step - loss: 3.5943\n",
      "Epoch 2/10\n",
      "585/585 [==============================] - 71s 121ms/step - loss: 3.1105\n",
      "Epoch 3/10\n",
      "585/585 [==============================] - 71s 121ms/step - loss: 2.9349\n",
      "Epoch 4/10\n",
      "585/585 [==============================] - 72s 123ms/step - loss: 2.7999\n",
      "Epoch 5/10\n",
      "585/585 [==============================] - 71s 121ms/step - loss: 2.6854\n",
      "Epoch 6/10\n",
      "585/585 [==============================] - 71s 122ms/step - loss: 2.5824\n",
      "Epoch 7/10\n",
      "585/585 [==============================] - 72s 123ms/step - loss: 2.4868\n",
      "Epoch 8/10\n",
      "585/585 [==============================] - 71s 122ms/step - loss: 2.3970\n",
      "Epoch 9/10\n",
      "585/585 [==============================] - 72s 124ms/step - loss: 2.3121\n",
      "Epoch 10/10\n",
      "585/585 [==============================] - 72s 123ms/step - loss: 2.2308\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fbed0094210>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True,\n",
    "    reduction='none'\n",
    ")\n",
    "\n",
    "model.compile(loss=loss, optimizer=optimizer)\n",
    "model.fit(dataset, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "standard-papua",
   "metadata": {},
   "source": [
    "## 최종적으로 loss값이 2.23이 나왔다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "governmental-appraisal",
   "metadata": {},
   "source": [
    "Embedding Size, Hidden size 조절  \n",
    "\n",
    "1. Embedding size 값이 커질수록 단어의 추상적인 특징들을 더 잡아낼 수 있지만, 그만큼 충분한 데이터가 주어지지 않으면 오히려 혼란만을 야기할 수 있습니다\n",
    "\n",
    "2. Hidden_size 도 같은 맥락입니다. hidden_size는 모델에 얼마나 많은 일꾼을 둘 것인가? 로 이해해도 크게 엇나가지 않습니다. 그 일꾼들은 모두 같은 데이터를 보고 각자의 생각을 가지는데, 역시 충분한 데이터가 주어지면 올바른 결정을 내리겠지만 그렇지 않으면 배가 산으로 갈 뿐 입니다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "atomic-swing",
   "metadata": {},
   "source": [
    "### 어느정도부터 데이터가 많다고 판단할 수 있는지 기준을 알지 못하지만 이번 경우는 데이터가 꽤 있는걸로 생각하고 두 size 값을 키워보겠다.(학습 시간이 오래걸려 한 번만 해보겠습니다.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "otherwise-mambo",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextGenerator(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_size, hidden_size):\n",
    "        super(TextGenerator, self).__init__()\n",
    "        \n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_size)\n",
    "        self.rnn_1 = tf.keras.layers.LSTM(hidden_size, return_sequences=True)\n",
    "        self.rnn_2 = tf.keras.layers.LSTM(hidden_size, return_sequences=True)\n",
    "        self.linear = tf.keras.layers.Dense(vocab_size)\n",
    "        \n",
    "    def call(self, x):\n",
    "        out = self.embedding(x)\n",
    "        out = self.rnn_1(out)\n",
    "        out = self.rnn_2(out)\n",
    "        out = self.linear(out)\n",
    "        \n",
    "        return out\n",
    "    \n",
    "embedding_size = 512\n",
    "hidden_size = 2048\n",
    "model_1 = TextGenerator(tokenizer.num_words + 1, embedding_size , hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "approximate-cruise",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(256, 13, 12001), dtype=float32, numpy=\n",
       "array([[[ 2.99034091e-05,  3.85609659e-04, -2.31016107e-04, ...,\n",
       "         -1.18975193e-04, -2.53126316e-04, -9.39094534e-05],\n",
       "        [ 3.43869106e-05,  4.80053975e-04, -6.08364295e-04, ...,\n",
       "         -2.68758845e-06, -3.42877349e-04,  1.07972146e-05],\n",
       "        [ 3.62009014e-04,  4.66183876e-04, -6.94188289e-04, ...,\n",
       "         -2.59679928e-05, -5.99983556e-04,  2.29985744e-04],\n",
       "        ...,\n",
       "        [ 1.46080274e-03,  4.59053525e-04, -1.22956373e-03, ...,\n",
       "          4.38354909e-04, -1.57323061e-03, -7.28417886e-04],\n",
       "        [ 1.47111702e-03,  5.36225503e-04, -1.16772542e-03, ...,\n",
       "          1.03938673e-03, -1.89471396e-03, -1.47234323e-03],\n",
       "        [ 1.42871123e-03,  5.58386382e-04, -1.08520349e-03, ...,\n",
       "          1.61250029e-03, -2.21406342e-03, -2.20094249e-03]],\n",
       "\n",
       "       [[ 2.99034091e-05,  3.85609659e-04, -2.31016107e-04, ...,\n",
       "         -1.18975193e-04, -2.53126316e-04, -9.39094534e-05],\n",
       "        [-3.28501657e-04,  7.35582551e-04,  9.33812407e-05, ...,\n",
       "         -6.85831474e-05, -5.00656141e-04, -2.04290773e-04],\n",
       "        [-8.14663304e-04,  7.14444439e-04,  3.33910757e-05, ...,\n",
       "          8.65260081e-05, -6.32080133e-04, -3.55940516e-04],\n",
       "        ...,\n",
       "        [-2.06054610e-04,  1.99441274e-04, -8.23556271e-04, ...,\n",
       "          1.15665479e-03, -2.07603420e-03, -2.25730240e-03],\n",
       "        [-1.51923377e-04,  1.35193099e-04, -7.70596263e-04, ...,\n",
       "          1.60915928e-03, -2.37239152e-03, -2.94545293e-03],\n",
       "        [-1.23797421e-04,  1.22216688e-05, -6.86877000e-04, ...,\n",
       "          1.98611850e-03, -2.62805610e-03, -3.56728001e-03]],\n",
       "\n",
       "       [[ 2.99034091e-05,  3.85609659e-04, -2.31016107e-04, ...,\n",
       "         -1.18975193e-04, -2.53126316e-04, -9.39094534e-05],\n",
       "        [ 3.39256658e-04,  7.91957485e-04, -3.47419555e-04, ...,\n",
       "         -2.14239808e-05, -2.15011314e-04,  2.81759829e-04],\n",
       "        [ 3.13411758e-04,  9.65885993e-04, -1.33322450e-04, ...,\n",
       "         -2.18983201e-04, -4.05890052e-04,  4.06498933e-04],\n",
       "        ...,\n",
       "        [ 6.66777545e-04, -6.75175324e-05, -6.34090859e-04, ...,\n",
       "         -9.00007260e-04, -9.33992211e-04,  1.06275454e-03],\n",
       "        [ 7.31680193e-04, -1.25066494e-04, -8.10897909e-04, ...,\n",
       "         -7.64878350e-04, -1.14877580e-03,  7.51422194e-04],\n",
       "        [ 8.11890350e-04, -8.17195105e-05, -8.59402178e-04, ...,\n",
       "         -3.54819902e-04, -1.44809962e-03,  1.36241244e-04]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 2.99034091e-05,  3.85609659e-04, -2.31016107e-04, ...,\n",
       "         -1.18975193e-04, -2.53126316e-04, -9.39094534e-05],\n",
       "        [ 2.49959558e-04,  3.56947741e-04, -4.04854480e-04, ...,\n",
       "         -5.79918385e-04, -2.65793002e-04, -4.37488925e-05],\n",
       "        [ 3.02866014e-04,  2.34752748e-04, -3.56172503e-04, ...,\n",
       "         -5.19115129e-04, -5.16782398e-04, -5.94196863e-05],\n",
       "        ...,\n",
       "        [-2.10027632e-04, -1.28953357e-03, -1.11838863e-05, ...,\n",
       "         -1.40317227e-03, -2.32701743e-04, -5.97599137e-04],\n",
       "        [-8.58014682e-05, -1.09056337e-03,  2.19338763e-05, ...,\n",
       "         -7.65649660e-04, -3.91845184e-04, -1.14978175e-03],\n",
       "        [ 1.54364661e-05, -8.97685473e-04,  7.58715541e-05, ...,\n",
       "         -4.31196167e-05, -6.59978716e-04, -1.80178310e-03]],\n",
       "\n",
       "       [[ 2.99034091e-05,  3.85609659e-04, -2.31016107e-04, ...,\n",
       "         -1.18975193e-04, -2.53126316e-04, -9.39094534e-05],\n",
       "        [-1.84433724e-04,  4.51025553e-04, -6.65905827e-05, ...,\n",
       "          4.53422435e-05, -1.04872524e-04, -3.07300565e-04],\n",
       "        [-8.65445400e-05,  4.69922059e-04, -3.92247512e-06, ...,\n",
       "         -1.29743275e-04, -9.80030236e-05, -8.53658348e-05],\n",
       "        ...,\n",
       "        [ 1.70936901e-03,  8.14686646e-05, -2.74495484e-04, ...,\n",
       "         -1.25079139e-04, -9.88332795e-06,  5.67331677e-04],\n",
       "        [ 1.60293642e-03,  1.22771438e-04, -3.10084928e-04, ...,\n",
       "          3.44945001e-05, -1.60392126e-04,  2.72762903e-04],\n",
       "        [ 1.53131445e-03,  2.71785451e-04, -3.08066519e-04, ...,\n",
       "          5.15024934e-04, -3.84350133e-04, -3.62703198e-04]],\n",
       "\n",
       "       [[ 2.99034091e-05,  3.85609659e-04, -2.31016107e-04, ...,\n",
       "         -1.18975193e-04, -2.53126316e-04, -9.39094534e-05],\n",
       "        [ 1.10683548e-04,  5.86716109e-04, -3.44035740e-04, ...,\n",
       "         -5.23249677e-04, -4.64043260e-04,  1.09818589e-04],\n",
       "        [ 7.72302701e-06,  8.89543560e-04, -4.81630850e-04, ...,\n",
       "         -8.12758284e-04, -1.47385770e-04,  3.23580171e-04],\n",
       "        ...,\n",
       "        [ 9.87420441e-04,  9.81748221e-04, -3.95339535e-04, ...,\n",
       "          1.92132965e-03, -1.89086492e-03, -2.86363903e-03],\n",
       "        [ 9.36125056e-04,  7.24570593e-04, -2.96448328e-04, ...,\n",
       "          2.26610829e-03, -2.24540313e-03, -3.39562912e-03],\n",
       "        [ 8.53793405e-04,  4.33311448e-04, -1.97133108e-04, ...,\n",
       "          2.51293369e-03, -2.54360423e-03, -3.86005593e-03]]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for src_sample, tgt_sample in dataset.take(1): break\n",
    "model_1(src_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "liquid-cedar",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"text_generator_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      multiple                  6144512   \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                multiple                  20979712  \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                multiple                  33562624  \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              multiple                  24590049  \n",
      "=================================================================\n",
      "Total params: 85,276,897\n",
      "Trainable params: 85,276,897\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fatal-compact",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "585/585 [==============================] - 211s 361ms/step - loss: 3.3613\n",
      "Epoch 2/10\n",
      "585/585 [==============================] - 214s 366ms/step - loss: 2.7644\n",
      "Epoch 3/10\n",
      "585/585 [==============================] - 214s 366ms/step - loss: 2.3793\n",
      "Epoch 4/10\n",
      "585/585 [==============================] - 214s 365ms/step - loss: 2.0255\n",
      "Epoch 5/10\n",
      "585/585 [==============================] - 215s 368ms/step - loss: 1.7161\n",
      "Epoch 6/10\n",
      "585/585 [==============================] - 216s 369ms/step - loss: 1.4706\n",
      "Epoch 7/10\n",
      "585/585 [==============================] - 215s 368ms/step - loss: 1.2917\n",
      "Epoch 8/10\n",
      "585/585 [==============================] - 215s 368ms/step - loss: 1.1741\n",
      "Epoch 9/10\n",
      "585/585 [==============================] - 214s 366ms/step - loss: 1.1080\n",
      "Epoch 10/10\n",
      "585/585 [==============================] - 214s 366ms/step - loss: 1.0726\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fcf31101b10>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True,\n",
    "    reduction='none'\n",
    ")\n",
    "\n",
    "model_1.compile(loss=loss, optimizer=optimizer)\n",
    "model_1.fit(dataset, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "successful-money",
   "metadata": {},
   "source": [
    "### 학습하는 동안 푹쉬다왔습니다... Size 값을 2배 올리니 loss값이 확연히 차이가 납니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "italic-humanitarian",
   "metadata": {},
   "source": [
    "# 가사생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "velvet-provider",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model_1, tokenizer, init_sentence=\"<start> i love\", max_len=20):\n",
    "    \n",
    "    test_input = tokenizer.texts_to_sequences([init_sentence])\n",
    "    test_tensor = tf.convert_to_tensor(test_input, dtype=tf.int64)\n",
    "    end_token = tokenizer.word_index[\"<end>\"]\n",
    "\n",
    "     \n",
    "    while True:\n",
    "        predict = model_1(test_tensor)  \n",
    "        predict_word = tf.argmax(tf.nn.softmax(predict, axis=-1), axis=-1)[:, -1]    \n",
    "\n",
    "        \n",
    "        test_tensor = tf.concat([test_tensor, \n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t tf.expand_dims(predict_word, axis=0)], axis=-1)\n",
    "\n",
    "        \n",
    "        if predict_word.numpy()[0] == end_token: break\n",
    "        if test_tensor.shape[1] >= max_len: break\n",
    "\n",
    "    generated = \"\"\n",
    "    \n",
    "    for word_index in test_tensor[0].numpy():\n",
    "        generated += tokenizer.index_word[word_index] + \" \"\n",
    "\n",
    "    return generated   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "micro-valuation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<start> i love you , i m not gonna crack <end> '"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(model_1, tokenizer, init_sentence=\"<start> i love\", max_len=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "geological-murder",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "divine-raise",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "joint-closer",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "secondary-chamber",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "searching-tobacco",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "heard-offense",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
